{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0cdf7b-9a83-4382-883e-8382f04b7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import nltk\n",
    "import numpy as num\n",
    "from nltk.stem import WordNetLemmatizer # It has the ability to lemmatize.\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8023c9de-ab0c-46b5-a58d-35b4c3acb5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ce7100-1ad6-44a4-8477-1d23e0d550a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:113: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:113: SyntaxWarning: invalid escape sequence '\\h'\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_4640\\1420559582.py:113: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  \"responses\": [\"You can contact us by \\n Phone: 010012345678 \\n Email: alpha@store.com \\n our help center: https://www.alpha-computer\\helpCenter\"]\n"
     ]
    }
   ],
   "source": [
    "graphics_cards = {\n",
    "                \"Colorful iGame GeForce RTX 3050 Ultra W DUO OC 8G-V 8GB GDDR6 Graphics Card\":\"11999LE\",\n",
    "                  \"GALAX GeForce RTX 3060 8GB 1-Click OC 8GB GDDR6 Graphics Card\":\"13500LE\",\n",
    "                  \"GALAX GeForce RTX 3060 Ti LHR 1-Click OC Feature 8GB GDDR6 Graphics Card\":\"16900LE\",\n",
    "                  \"Colorful GeForce GTX 1660 SUPER NB 6GB V2-V GDDR6 Graphics Card\":\"8900LE\",\n",
    "                  \"COLORFUL IGAME GEFORCE RTX 3060 ULTRA W OC 12G L-V Graphics Card\":\"15000LE\",\n",
    "                  \"ASUS TUF Gaming GeForce RTX 3090 OC 24G\":\"39500LE\",\n",
    "                    \"GIGABAYT GeForce RTX 2060 WINDFORCE OC 12G\":\"10999LE\"\n",
    "                 }\n",
    "gc_s = {\n",
    "                \"Colorful iGame GeForce RTX 3050 Ultra W DUO OC 8G-V 8GB GDDR6 Graphics Card\":\"Colorful iGame RTX 3050 8GB GDDR6\",\n",
    "                  \"GALAX GeForce RTX 3060 8GB 1-Click OC 8GB GDDR6 Graphics Card\":\"GALAX RTX 3060 8GB\",\n",
    "                  \"GALAX GeForce RTX 3060 Ti LHR 1-Click OC Feature 8GB GDDR6 Graphics Card\":\"RTX 3060 Ti\",\n",
    "                  \"Colorful GeForce GTX 1660 SUPER NB 6GB V2-V GDDR6 Graphics Card\":\"GTX 1660 SUPER 6GB\",\n",
    "                  \"COLORFUL IGAME GEFORCE RTX 3060 ULTRA W OC 12G L-V Graphics Card\":\"GEFORCE RTX 3060 ULTRA\",\n",
    "                  \"ASUS TUF Gaming GeForce RTX 3090 OC 24G\":\"RTX 3090 OC 24G\",\n",
    "                    \"GIGABAYT GeForce RTX 2060 WINDFORCE OC 12G\":\"RTX 2060 WINDFORCE OC 12G\"\n",
    "                 }\n",
    "\n",
    "\n",
    "\n",
    "processors =  {\"INTEL CORE I5 10400F TRAY Processor\":\"4299LE\",\n",
    "               \"Intel Core i9-13900K Processor\":\"23900LE\",\n",
    "               \"Intel Core i9 13900 24 Cores 32 Threads Max Turbo 5.6GHz 36MB Cache LGA 1700 Socket 13th Gen Raptor Lake\":\"22350LE\",\n",
    "               \"AMD Ryzen 7 5800X BOX Desktop Processors (8 CORE-16 THREAD) (32M CACHE/3.8GHz/UP TO 4.7GHz)\":\"9199LE\",\n",
    "               \"AMD Ryzen 5 3600 TRAY-6CORE-12THREAD-32M CACH/3.6GHZ up to 4.2GHZ-PCIe 4.0\":\"3700LE\"\n",
    "               \n",
    "              }\n",
    "p_s =  {\"INTEL CORE I5 10400F TRAY Processor\":\"CORE I5 10400F\",\n",
    "               \"Intel Core i9-13900K Processor\":\"Core i9-13900K\",\n",
    "               \"Intel Core i9 13900 24 Cores 32 Threads Max Turbo 5.6GHz 36MB Cache LGA 1700 Socket 13th Gen Raptor Lake\":\"Core i9 13900\",\n",
    "               \"AMD Ryzen 7 5800X BOX Desktop Processors (8 CORE-16 THREAD) (32M CACHE/3.8GHz/UP TO 4.7GHz)\":\"AMD Ryzen 7 5800X\",\n",
    "               \"AMD Ryzen 5 3600 TRAY-6CORE-12THREAD-32M CACH/3.6GHZ up to 4.2GHZ-PCIe 4.0\":\"AMD Ryzen 5 3600\"}\n",
    "\n",
    "ram = {\"HyperX Impact 8GB DDR4 3200MHz Memory RAM SODIMM\":\"850\",\n",
    "       \"DATO RAM 32GB DDR4 P2666 NOTEBOOK\":\"2600\",\n",
    "       \"Crucial 8GB DDR4-3200 SODIMM 1.2V CL22 LAPTOP\":\"730\",\n",
    "       \"LEXAR RAM 8G P2666 CL22 SODIMM NOTEBOOK\":\"650\",\n",
    "       \"RAM-TEAM-ELITE-16G-3200HZ-NB-Cl22-22-22\":\"1600\"\n",
    "    \n",
    "}\n",
    "\n",
    "r_s = {\"HyperX Impact 8GB DDR4 3200MHz Memory RAM SODIMM\":\"8GB RAM\",\n",
    "       \"DATO RAM 32GB DDR4 P2666 NOTEBOOK\":\"32GB RAM\",\n",
    "       \"Crucial 8GB DDR4-3200 SODIMM 1.2V CL22 LAPTOP\":\"8GB RAM\",\n",
    "       \"LEXAR RAM 8G P2666 CL22 SODIMM NOTEBOOK\":\"8GB RAM\",\n",
    "       \"RAM-TEAM-ELITE-16G-3200HZ-NB-Cl22-22-22\":\"16GB RAM\"\n",
    "    \n",
    "}\n",
    "\n",
    "data = {\"intents\": [\n",
    "\n",
    "          {\"tag\": \"greeting\",\n",
    "          \"patterns\": [\"Hi\",\"How are you?\",\"Is anyone there?\",\"Hello\",\"Good day\",\"What's up\",\"Good Morning\",\"how are ya\",\"heyy\",\"whatsup\",\n",
    "      \"??? ??? ??\"],\n",
    "          \"responses\": [\"Hi how can I serve you?\"],\n",
    "         },\n",
    "        {\"tag\": \"pleasure\",\n",
    "          \"patterns\": [ \"It was a pleasure to meet you.\",\"It is a pleasure to meet you.\",\"It was nice to meet you.\",\"Lovely to meet you.\",\"Great to meet you!\",\"Glad to meet you.\",\"Nice meeting you.\",\"Pleasure to meet you.\",\"It was an honor to meet you.\",\"It was a pleasure meeting you.\",\"Looking forward to meeting you again.\",\"It's a pleasure to finally meet you.\",\"It was a pleasure to meet someone with your expertise.\",\"Hi! Nice to meet you.\",\"Hey there!\",\"Howdy!\",\"Well, this is a nice surprise!\"],\n",
    "          \"responses\": [\"thanks it was a pleasure to meet you too\"],\n",
    "         },\n",
    "          {\"tag\": \"goodbye\",\n",
    "          \"patterns\": [ \"bye\", \"later\",\"goodbye\",\"see you later\", \"Goodbye!\", \"Bye!\", \"See ya!\", \"Later!\", \"Cya!\", \"Gotta go!\", \"Talk to you later!\", \"Adios!\", \"Ciao!\", \"Catch you later!\", \"Take care!\", \"Peace out!\", \"TTYL!\", \"Brb!\", \"Off now!\", \"Later gator!\",\"See ya in a bit!\", \"Deuces!\"],\n",
    "          \"responses\": [\"It was nice to serve you\"]\n",
    "        },\n",
    "         {\"tag\": \"name\",\n",
    "          \"patterns\": [\"What's your name?\", \"What should I call you?\", \"What's up, stranger?\", \"What's your username?\", \"Mind if I know your name?\", \"How can I address you?\", \"Hey there! What's your name?\", \"Yo, what's your name?\", \"Name's me, what's yours?\", \"What's the name?\", \"Spill the beans, who are you?\", \"Let's get acquainted, what's your name?\", \"Curious, what's your name?\",\"Introduce yourself? \", \"What should I call this amazing person?\",  \"Name please? (so I don't call you dude all the time)\"],\n",
    "          \"responses\": [\"My name is Alphabot, I was created by ALPHA COMPUTER STORE to help our customers tom make thier descisions about shopping for our products\"]\n",
    "         },\n",
    "         {\n",
    "          \"tag\": \"website\",\n",
    "          \"patterns\": [\"How can I order?\", \"How to order online?\", \"Can I order online?\",\n",
    "            \"How can I order something from your website?\", \"I want to make an order\",\n",
    "            \"I want the link of your website\", \"What products do you have?\",\n",
    "            \"How do I order something?\", \"I want to see your products\",\n",
    "            \"Looking to place an order, how do I do that?\",  # More explicit\n",
    "            \"Can I buy something online?\",  # Simpler way of asking about ordering\n",
    "            \"Do you have an online store?\",  # Asks about online ordering possibility\n",
    "            \"Is there a way to purchase your products online?\",  # More formal inquiry\n",
    "            \"Need to place an order, what are the options?\",  # Asks for ordering details\n",
    "            \"I'm interested in ordering. Can you tell me how?\",  # Shows buying intent\n",
    "            \"Let me know how I can buy something from you.\",  # Direct request\n",
    "            \"Website question: How can I order?\",  # Clarifies website purpose\n",
    "            \"Just browsing, but curious about ordering?\",  # Browsing with intent\n",
    "            \"Is there a menu/catalog I can look at to order?\",  # Asks for product info\n",
    "            \"Ready to buy! How do I place an order?\"],\n",
    "          \"responses\": [\"You can shop and order our products at our website https://www.alpha-computer.com\"]     \n",
    "        },\n",
    "        {\n",
    "          \"tag\": \"About us\",\n",
    "          \"patterns\": [    \"How can I order?\", \"How to order online?\", \"Can I order online?\",\n",
    "                        \"How can I order something from your website?\", \"I want to make an order\",\n",
    "                        \"I want the link of your website\", \"What products do you have?\",\n",
    "                        \"How do I order something?\", \"I want to see your products\",\n",
    "                        \"Looking to place an order, how do I do that?\",  # More explicit\n",
    "                        \"Can I buy something online?\",  # Simpler way of asking about ordering\n",
    "                        \"Do you have an online store?\",  # Asks about online ordering possibility\n",
    "                        \"Is there a way to purchase your products online?\",  # More formal inquiry\n",
    "                        \"Need to place an order, what are the options?\",  # Asks for ordering details\n",
    "                        \"I'm interested in ordering. Can you tell me how?\",  # Shows buying intent\n",
    "                        \"Let me know how I can buy something from you.\",  # Direct request\n",
    "                        \"Website question: How can I order?\",  # Clarifies website purpose\n",
    "                        \"Just browsing, but curious about ordering?\",  # Browsing with intent\n",
    "                        \"Is there a menu/catalog I can look at to order?\",  # Asks for product info\n",
    "                        \"Ready to buy! How do I place an order?\"  ],\n",
    "          \"responses\": [\"We are Alpha store,  We are specializing in retail and wholesale electronics including laptops, computers and accessories. \\n\\nwe sell : \\n 1-Graphics Cards \\n 2-Processors \\n 3-Ram \\n 4-Motherboards \\n 5-Power Supplyies \\n 6-Storage Cards \\n 7-Monitors \\n 8-Electronic accessories \\n \\n and many other products\"]     \n",
    "        },\n",
    "        {\n",
    "          \"tag\": \"contact us\",\n",
    "          \"patterns\": [\"What's your phone number?\", \"Phone number, please?\", \"Could you share your phone number?\", \"Can I have your phone number?\", \"Your phone number, please?\", \"May I get your phone number?\", \"Could you provide your phone number?\", \"What's your contact number?\", \"Can you give me your phone number?\", \"Could you please share your phone number?\", \"What's your cellphone number?\", \"Your phone number, if you don't mind?\", \"May I know your phone number?\", \"Could you tell me your phone number?\", \"Can you provide your phone number?\", \"What is your email?\", \"Could you please share your email?\", \"What's your email address?\", \"Can I have your email?\", \"Your email, please?\"],\n",
    "          \"responses\": [\"You can contact us by \\n Phone: 010012345678 \\n Email: alpha@store.com \\n our help center: https://www.alpha-computer\\helpCenter\"]     \n",
    "        },\n",
    "        {\"tag\": \"thanks\",\n",
    "          \"patterns\": [\"Thank you\", \"Thankyou\", \"Thanks you helped me a lot\", \"Thanks for the help\", \"Thanks a bunch\", \"Thanks a ton\", \"Thanks a million\", \"Thank you so much\", \"Thanks a bunch for your assistance\", \"Appreciate your help\", \"Thanks for your support\", \"Much appreciated\", \"Thank you very much\", \"Thanks for everything\", \"Thank you kindly\", \"Thanks for your time\", \"Thank you for your kindness\", \"Thanks a heap\", \"Thanks for your guidance\", \"Thanks for being so helpful\"],\n",
    "          \"responses\": [\"I am always happy to help\"],\n",
    "         }\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "             \n",
    "    \n",
    "\n",
    "]}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8eedf4e-54a8-4eb4-a7ca-734d06da09b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in graphics_cards:\n",
    "    data[\"intents\"].append(\n",
    "        {\n",
    "          \"tag\": f\"Graphics cards or GPU : {key}\",\n",
    "          \n",
    "            \"patterns\": [f\"I want to order {key}\",f\"I want to make an order for {key}\",f\"is {key} available\",f'I want a {key}'\n",
    "                       ,f\"do you have{key}\",f\"I want to order {gc_s[key]}\",f\"I want to make an order for {gc_s[key]}\",\n",
    "                       f\"is {gc_s[key]} available\",f'I want a {gc_s[key]}',f\"do you have{gc_s[key]}\"],\n",
    "          \n",
    "            \"responses\": [f\"You can find '{key}' in our website https://www.alpha-computer/LINK_FOR_PRODUCT.com\"]     \n",
    "        }\n",
    "    )\n",
    "    data[\"intents\"].append(\n",
    "    {\n",
    "          \"tag\": f\"Graphics cards or GPU cost : {key}\",\n",
    "          \"patterns\": [f\" how much is {key}\",f\" how much does {key} cost\",f\"I want to make an order for {key} how much does it cost\",f\"is {key} cost alot?\",\n",
    "                      f\"I want to make an order for {gc_s[key]}\",f\"is {gc_s[key]} available\",f'I want a {gc_s[key]}',f\"do you have{gc_s[key]}\"],\n",
    "          \"responses\": [f\"You can consider '{key}' from our store with only '{graphics_cards[key]}' take a look to it in https://www.alpha-computer/LINK_FOR_PRODUCT.com\"]     \n",
    "        }\n",
    "    )\n",
    "\n",
    "for key in processors:\n",
    "    data[\"intents\"].append(\n",
    "        {\n",
    "          \"tag\": f\"Processors or CPU: {key}\",\n",
    "          \"patterns\": [f\"I want to order {key}\",f\"I want to make an order for {key}\",f\"is {key} available\",\n",
    "                      f\"I want to order {p_s[key]}\",f\"I want to make an order for {p_s[key]}\",f\"is {p_s[key]} available\",\n",
    "                       f'I want a {p_s[key]}',f\"do you have{p_s[key]}\"],\n",
    "          \"responses\": [f\"You can find '{key}' and many other processors models in our website https://www.alpha-computer/LINK_FOR_PRODUCT.com\"]     \n",
    "        }\n",
    "    )\n",
    "    data[\"intents\"].append(\n",
    "    {\n",
    "          \"tag\": f\"Processors or CPU cost : {key}\",\n",
    "          \"patterns\": [f\"I want to order {key}\",f\" how much is {key}\",f\" how much does {key} cost\",\n",
    "                       f\"I want to make an order for {key} how much does it cost\",f\"is {key} cost alot?\",\n",
    "                       f\"which models of {key} do you have\",f\"I want to make an order for {p_s[key]}\",\n",
    "                       f\"is {p_s[key]} available\",f'I want a {p_s[key]}',f\"do you have{p_s[key]}\"],\n",
    "          \"responses\": [f\"You can consider '{key}' from our store with only '{processors[key]}' take a look at our online shop in https://www.alpha-computer/LINK_FOR_PRODUCT.com\"]     \n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "gc_list= 'We offer many models of graphics cards this is a list of our top requisted products:\\n\\n'\n",
    "for i, key in enumerate(graphics_cards):\n",
    "    gc_list += f\"{i+1}- {key} \\n price: {graphics_cards[key]}\\n\\n\"\n",
    "\n",
    "pc_list= 'We offer many models of Processors this is a list of our top requisted products:\\n\\n'\n",
    "for i, key in enumerate(processors):\n",
    "    pc_list += f\"{i+1}- '{key}' \\n price: {processors[key]}\\n\\n\"\n",
    "\n",
    "ram_list= 'We offer many models of Rams this is a list of our top requisted products:\\n\\n'\n",
    "for i, key in enumerate(processors):\n",
    "    pc_list += f\"{i+1}- '{key}' \\n price: {processors[key]}\\n\\n\"\n",
    "\n",
    "\n",
    "data[\"intents\"].append(\n",
    "        {\n",
    "          \"tag\": f\"Graphics cards list\",\n",
    "          \"patterns\": [f\"What kind of graphics cards do you have?\",\"list me the gpus that you are selling\",\"list me the every gpu you are selling\",\"recommend a Graphics card for me\",f\"I want a Graphics card\",\"I want gtx or rtx\",\"I want a Gtx graphics card\",\"I want a Rtx graphics card\",\"I am missing a graphics card\",\"which graphics cards do you offer?\",\"suggest a graphics card for me\",\"do you sell graphics card?\",\"do you have graphics card?\",\"do you have good graphics card to sell?\",\"what kind of graphics card do you have?\",\"suggest a graphics card for me\",\n",
    "                      f\"What kind of GPU do you have?\",\"list me the Graphics cards that you are selling\",\"list me the every Graphics card you are selling\",\"recommend a GPU for me\",f\"I want a GPU\",\"I want gtx or rtx\",\"I want a Gtx GPU\",\"I want a Rtx GPU\",\"I am missing a GPU\",\"which GPU do you offer?\",\"suggest a GPU for me\",\"do you sell GPU?\",\"do you have GPU?\",\"do you have good GPU to sell?\",\"what kind of GPU do you have?\",\"suggest a GPU for me\",\"I also need a gpu\"],\n",
    "          \"responses\": [gc_list]     \n",
    "        }\n",
    "    )\n",
    "data[\"intents\"].append(\n",
    "        {\n",
    "          \"tag\": f\"Processor list\",\n",
    "          \"patterns\": [f\"What kind of Processors do you have?\",\"list me the processors that you are selling\",\"recommend a Processor for me\",f\"I want a Processor\",\"I want Intel or AMD\",\"I am missing a processor\",\"which model of processors do you offer?\",\"do you sell processors?\",\"do you have processors?\",\"do you have good processors to sell?\",\"what kind of processors do you have?\",\"suggest a processor for me\",\"I also need a processor\",\n",
    "                      f\"What kind of CPUs do you have?\",\"list me the CPUs that you are selling\",\"recommend a CPU for me\",f\"I want a CPU\",\"I want Intel or AMD\",\"I am missing a CPU\",\"which model of CPU do you offer?\",\"do you sell CPU?\",\"do you have CPUs?\",\"do you have good CPUs to sell?\",\"what kind of CPUs do you have?\",\"suggest a CPU for me\",\"I also need a CPU\"],\n",
    "          \"responses\": [pc_list]     \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4be6d5-af21-4363-bd62-85a1ee94df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer() #for getting words\n",
    "# lists\n",
    "ourClasses = []\n",
    "newWords = []\n",
    "documentX = []\n",
    "documentY = []\n",
    "MAX_length = 0\n",
    "input_sizes = [32,64,128,256,512,1024]\n",
    "# Each intent is tokenized into words and the patterns and their associated tags are added to their respective lists.\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        ournewTkns = nltk.word_tokenize(pattern)# tokenize the patterns\n",
    "        MAX_length = max([MAX_length, len(pattern)])\n",
    "        \n",
    "        documentX.append(\"[CLS] \" + pattern)\n",
    "        documentY.append(intent[\"tag\"])\n",
    "\n",
    "\n",
    "    if intent[\"tag\"] not in ourClasses:# add unexisting tags to their respective classes\n",
    "        ourClasses.append(intent[\"tag\"])\n",
    "\n",
    "\n",
    "for i in range(len(input_sizes)):\n",
    "    if MAX_length <  input_sizes[i]:\n",
    "        MAX_length = input_sizes[i]\n",
    "        break\n",
    "\n",
    "\n",
    "ourClasses = sorted(set(ourClasses))# sorting classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7858aff-a884-4856-9094-4a5992f1dc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc954754-bf3b-4b0b-a67e-04a621ccb57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(MAX_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a4b302b-4800-4128-858f-8b954843ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define a custom dataset class to handle data loading\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y, tokenizer, max_length):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.Y_encoded = self.label_encoder.fit_transform(Y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.X[idx]\n",
    "   \n",
    "        label = torch.tensor(self.Y_encoded[idx])\n",
    "\n",
    "        \n",
    "        # Tokenize input text\n",
    "        encoding = self.tokenizer(text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt')\n",
    "\n",
    "        input_ids = encoding['input_ids']\n",
    "       \n",
    "        attention_mask = encoding['attention_mask']\n",
    "\n",
    "        return input_ids, attention_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508cfb4c-24ca-44ea-b32e-4c5bf8029363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ourClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c843a804-b045-489d-a17d-28b0b0e8fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Documents\\GitHub\\mostafa_gp\\chatbot\\torchenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at shahrukhx01/question-vs-statement-classifier and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([34]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 256]) in the checkpoint and torch.Size([34, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 256, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 256)\n",
       "      (token_type_embeddings): Embedding(2, 256)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=256, out_features=34, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification , AutoModelForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/question-vs-statement-classifier\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/question-vs-statement-classifier\", \n",
    "                                                           num_labels=len(ourClasses),ignore_mismatched_sizes=True\n",
    "                                                         )\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6695842-70a5-43fe-ac83-db94ae262ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16\n",
    "epochs= 100\n",
    "# Define train loader\n",
    "train_dataset = CustomDataset(documentX, documentY, tokenizer, max_length= MAX_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b029fd-011f-484b-9652-4acc5c7b0034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Documents\\GitHub\\mostafa_gp\\chatbot\\torchenv\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted tensor([20, 20, 27, 20, 20], device='cuda:0')\n",
      "True  tensor([ 8, 20, 29, 28,  1], device='cuda:0')\n",
      "Epoch [1/100], Loss: 3.5447, Accuracy: 0.0356\n",
      "predicted tensor([30,  5, 15, 28, 17], device='cuda:0')\n",
      "True  tensor([31,  8,  4, 23,  9], device='cuda:0')\n",
      "Epoch [2/100], Loss: 3.5049, Accuracy: 0.0546\n",
      "predicted tensor([33, 20, 27,  4, 33], device='cuda:0')\n",
      "True  tensor([27,  5, 10, 21, 20], device='cuda:0')\n",
      "Epoch [3/100], Loss: 3.4776, Accuracy: 0.0736\n",
      "predicted tensor([28, 27, 28, 28, 28], device='cuda:0')\n",
      "True  tensor([ 1, 27, 25, 32,  1], device='cuda:0')\n",
      "Epoch [4/100], Loss: 3.4339, Accuracy: 0.1045\n",
      "predicted tensor([33, 28, 20, 28, 27], device='cuda:0')\n",
      "True  tensor([29, 26,  9, 33, 12], device='cuda:0')\n",
      "Epoch [5/100], Loss: 3.4110, Accuracy: 0.1093\n",
      "predicted tensor([27, 28, 28, 17, 26], device='cuda:0')\n",
      "True  tensor([ 9, 28, 24, 14,  6], device='cuda:0')\n",
      "Epoch [6/100], Loss: 3.3826, Accuracy: 0.1235\n",
      "predicted tensor([ 4, 27, 33, 28, 27], device='cuda:0')\n",
      "True  tensor([ 3, 33,  1, 33, 27], device='cuda:0')\n",
      "Epoch [7/100], Loss: 3.3664, Accuracy: 0.1164\n",
      "predicted tensor([28, 33, 28, 28, 28], device='cuda:0')\n",
      "True  tensor([ 3,  1, 16, 32, 16], device='cuda:0')\n",
      "Epoch [8/100], Loss: 3.3399, Accuracy: 0.1188\n",
      "predicted tensor([28, 33,  4, 28, 28], device='cuda:0')\n",
      "True  tensor([22, 30, 11,  2,  0], device='cuda:0')\n",
      "Epoch [9/100], Loss: 3.3027, Accuracy: 0.1306\n",
      "predicted tensor([33, 28, 32, 28, 33], device='cuda:0')\n",
      "True  tensor([13, 31, 32, 19, 30], device='cuda:0')\n",
      "Epoch [10/100], Loss: 3.2753, Accuracy: 0.1876\n",
      "predicted tensor([ 1,  1,  9,  2, 28], device='cuda:0')\n",
      "True  tensor([25, 20,  9,  4,  7], device='cuda:0')\n",
      "Epoch [11/100], Loss: 3.2541, Accuracy: 0.2043\n",
      "predicted tensor([33, 33,  4,  1, 32], device='cuda:0')\n",
      "True  tensor([ 1, 29,  7, 16, 32], device='cuda:0')\n",
      "Epoch [12/100], Loss: 3.2188, Accuracy: 0.2328\n",
      "predicted tensor([20, 20, 32,  0,  1], device='cuda:0')\n",
      "True  tensor([23, 13, 32, 19, 25], device='cuda:0')\n",
      "Epoch [13/100], Loss: 3.1969, Accuracy: 0.2257\n",
      "predicted tensor([ 1, 18, 33, 17,  1], device='cuda:0')\n",
      "True  tensor([22, 22, 29, 17, 16], device='cuda:0')\n",
      "Epoch [14/100], Loss: 3.1566, Accuracy: 0.2732\n",
      "predicted tensor([33, 28,  1, 28,  1], device='cuda:0')\n",
      "True  tensor([10, 28,  1,  4, 22], device='cuda:0')\n",
      "Epoch [15/100], Loss: 3.1230, Accuracy: 0.2732\n",
      "predicted tensor([ 2, 33, 27,  1, 33], device='cuda:0')\n",
      "True  tensor([ 5, 33,  1,  1, 33], device='cuda:0')\n",
      "Epoch [16/100], Loss: 3.0953, Accuracy: 0.2660\n",
      "predicted tensor([32,  1,  8, 33, 17], device='cuda:0')\n",
      "True  tensor([32,  1, 15, 27, 22], device='cuda:0')\n",
      "Epoch [17/100], Loss: 3.0585, Accuracy: 0.3373\n",
      "predicted tensor([32,  1, 33,  2,  1], device='cuda:0')\n",
      "True  tensor([ 8, 19,  0,  6,  1], device='cuda:0')\n",
      "Epoch [18/100], Loss: 3.0315, Accuracy: 0.3159\n",
      "predicted tensor([20, 28, 20,  1, 27], device='cuda:0')\n",
      "True  tensor([14, 28,  5, 16, 33], device='cuda:0')\n",
      "Epoch [19/100], Loss: 3.0018, Accuracy: 0.3420\n",
      "predicted tensor([32, 33,  8, 27,  5], device='cuda:0')\n",
      "True  tensor([32, 30,  9, 33,  7], device='cuda:0')\n",
      "Epoch [20/100], Loss: 2.9568, Accuracy: 0.3634\n",
      "predicted tensor([16,  8, 33, 27,  1], device='cuda:0')\n",
      "True  tensor([ 1,  8,  0, 16,  1], device='cuda:0')\n",
      "Epoch [21/100], Loss: 2.9399, Accuracy: 0.3492\n",
      "predicted tensor([ 8,  1, 31, 32, 17], device='cuda:0')\n",
      "True  tensor([ 2,  1, 31, 32, 17], device='cuda:0')\n",
      "Epoch [22/100], Loss: 2.8936, Accuracy: 0.3777\n",
      "predicted tensor([ 5,  2, 19, 31,  5], device='cuda:0')\n",
      "True  tensor([ 5,  8, 12, 31,  4], device='cuda:0')\n",
      "Epoch [23/100], Loss: 2.8654, Accuracy: 0.4014\n",
      "predicted tensor([15,  1,  2, 32,  2], device='cuda:0')\n",
      "True  tensor([ 9,  1, 14, 21, 13], device='cuda:0')\n",
      "Epoch [24/100], Loss: 2.8287, Accuracy: 0.4299\n",
      "predicted tensor([ 8, 27, 12,  5, 27], device='cuda:0')\n",
      "True  tensor([ 8, 30, 19,  5, 27], device='cuda:0')\n",
      "Epoch [25/100], Loss: 2.7956, Accuracy: 0.4276\n",
      "predicted tensor([ 1,  3,  5, 27,  7], device='cuda:0')\n",
      "True  tensor([ 1,  3,  6, 27,  6], device='cuda:0')\n",
      "Epoch [26/100], Loss: 2.7680, Accuracy: 0.4489\n",
      "predicted tensor([ 2, 26, 29,  2,  2], device='cuda:0')\n",
      "True  tensor([ 7, 24, 21, 17,  9], device='cuda:0')\n",
      "Epoch [27/100], Loss: 2.7196, Accuracy: 0.4869\n",
      "predicted tensor([16, 24, 33, 27, 16], device='cuda:0')\n",
      "True  tensor([16, 25, 27, 31, 16], device='cuda:0')\n",
      "Epoch [28/100], Loss: 2.7010, Accuracy: 0.4917\n",
      "predicted tensor([18, 19, 33,  4,  4], device='cuda:0')\n",
      "True  tensor([25, 19, 33, 11,  4], device='cuda:0')\n",
      "Epoch [29/100], Loss: 2.6551, Accuracy: 0.5083\n",
      "predicted tensor([33, 16, 17, 10,  5], device='cuda:0')\n",
      "True  tensor([ 0, 16, 22, 15, 12], device='cuda:0')\n",
      "Epoch [30/100], Loss: 2.6165, Accuracy: 0.5202\n",
      "predicted tensor([33, 20, 33, 16,  5], device='cuda:0')\n",
      "True  tensor([33, 25, 33, 16,  3], device='cuda:0')\n",
      "Epoch [31/100], Loss: 2.5926, Accuracy: 0.5392\n",
      "predicted tensor([ 2, 25, 16,  4, 27], device='cuda:0')\n",
      "True  tensor([ 9, 19,  1,  4, 27], device='cuda:0')\n",
      "Epoch [32/100], Loss: 2.5570, Accuracy: 0.5724\n",
      "predicted tensor([ 5, 31, 18, 13, 26], device='cuda:0')\n",
      "True  tensor([ 5, 31, 18, 11, 21], device='cuda:0')\n",
      "Epoch [33/100], Loss: 2.5236, Accuracy: 0.5534\n",
      "predicted tensor([ 5, 33, 16, 26, 19], device='cuda:0')\n",
      "True  tensor([11, 33, 16, 21, 19], device='cuda:0')\n",
      "Epoch [34/100], Loss: 2.4947, Accuracy: 0.5796\n",
      "predicted tensor([16, 33, 16, 28,  5], device='cuda:0')\n",
      "True  tensor([16, 30, 16, 28,  5], device='cuda:0')\n",
      "Epoch [35/100], Loss: 2.4628, Accuracy: 0.5867\n",
      "predicted tensor([32, 16, 20,  2, 16], device='cuda:0')\n",
      "True  tensor([32, 16, 20,  2, 16], device='cuda:0')\n",
      "Epoch [36/100], Loss: 2.4278, Accuracy: 0.6081\n",
      "predicted tensor([26, 28,  4,  1, 33], device='cuda:0')\n",
      "True  tensor([25, 28,  4,  0, 33], device='cuda:0')\n",
      "Epoch [37/100], Loss: 2.3955, Accuracy: 0.5986\n",
      "predicted tensor([33,  9,  8, 20,  1], device='cuda:0')\n",
      "True  tensor([33,  9, 15, 25,  1], device='cuda:0')\n",
      "Epoch [38/100], Loss: 2.3559, Accuracy: 0.6437\n",
      "predicted tensor([28,  5,  7, 26,  0], device='cuda:0')\n",
      "True  tensor([28, 12, 13, 26, 30], device='cuda:0')\n",
      "Epoch [39/100], Loss: 2.3371, Accuracy: 0.6532\n",
      "predicted tensor([ 5,  1,  1, 27, 33], device='cuda:0')\n",
      "True  tensor([ 6,  1,  1, 27,  0], device='cuda:0')\n",
      "Epoch [40/100], Loss: 2.2993, Accuracy: 0.6342\n",
      "predicted tensor([19, 28, 33, 27,  1], device='cuda:0')\n",
      "True  tensor([19, 28,  0, 27,  1], device='cuda:0')\n",
      "Epoch [41/100], Loss: 2.2815, Accuracy: 0.6627\n",
      "predicted tensor([ 4, 20, 16, 24, 21], device='cuda:0')\n",
      "True  tensor([11, 20, 16, 19, 21], device='cuda:0')\n",
      "Epoch [42/100], Loss: 2.2433, Accuracy: 0.6603\n",
      "predicted tensor([ 4,  0, 20, 27, 16], device='cuda:0')\n",
      "True  tensor([ 4, 30, 20, 27, 16], device='cuda:0')\n",
      "Epoch [43/100], Loss: 2.2034, Accuracy: 0.6817\n",
      "predicted tensor([12,  3,  4,  1,  4], device='cuda:0')\n",
      "True  tensor([12,  3, 11,  1, 11], device='cuda:0')\n",
      "Epoch [44/100], Loss: 2.1905, Accuracy: 0.6651\n",
      "predicted tensor([28,  1,  6,  6,  8], device='cuda:0')\n",
      "True  tensor([29,  1,  6,  6,  8], device='cuda:0')\n",
      "Epoch [45/100], Loss: 2.1642, Accuracy: 0.6817\n",
      "predicted tensor([ 4, 13,  5, 20, 28], device='cuda:0')\n",
      "True  tensor([ 4, 13,  5, 25, 28], device='cuda:0')\n",
      "Epoch [46/100], Loss: 2.1287, Accuracy: 0.7102\n",
      "predicted tensor([24, 16,  2,  4, 16], device='cuda:0')\n",
      "True  tensor([24, 16,  9,  4, 16], device='cuda:0')\n",
      "Epoch [47/100], Loss: 2.0932, Accuracy: 0.7126\n",
      "predicted tensor([ 3,  7, 33, 33,  1], device='cuda:0')\n",
      "True  tensor([10,  7,  0,  0,  1], device='cuda:0')\n",
      "Epoch [48/100], Loss: 2.0679, Accuracy: 0.6936\n",
      "predicted tensor([27,  5, 15, 32, 12], device='cuda:0')\n",
      "True  tensor([27, 11, 15, 32, 12], device='cuda:0')\n",
      "Epoch [49/100], Loss: 2.0443, Accuracy: 0.7435\n",
      "predicted tensor([33,  4, 27,  1, 32], device='cuda:0')\n",
      "True  tensor([29, 11, 27,  1, 32], device='cuda:0')\n",
      "Epoch [50/100], Loss: 2.0260, Accuracy: 0.7173\n",
      "predicted tensor([17, 29, 33, 18,  8], device='cuda:0')\n",
      "True  tensor([22, 29, 33, 23,  8], device='cuda:0')\n",
      "Epoch [51/100], Loss: 1.9865, Accuracy: 0.7482\n",
      "predicted tensor([28, 28, 21, 20,  6], device='cuda:0')\n",
      "True  tensor([28, 28, 21, 20,  6], device='cuda:0')\n",
      "Epoch [52/100], Loss: 1.9609, Accuracy: 0.7173\n",
      "predicted tensor([13, 30, 16,  1,  2], device='cuda:0')\n",
      "True  tensor([13, 30, 16,  1,  9], device='cuda:0')\n",
      "Epoch [53/100], Loss: 1.9352, Accuracy: 0.7363\n",
      "predicted tensor([ 6, 28, 16,  2, 33], device='cuda:0')\n",
      "True  tensor([ 6, 28, 16,  2,  0], device='cuda:0')\n",
      "Epoch [54/100], Loss: 1.9168, Accuracy: 0.7292\n",
      "predicted tensor([ 7,  4, 26,  7, 32], device='cuda:0')\n",
      "True  tensor([ 7,  4, 21, 14, 32], device='cuda:0')\n",
      "Epoch [55/100], Loss: 1.8955, Accuracy: 0.7197\n",
      "predicted tensor([ 7, 17, 28,  1,  6], device='cuda:0')\n",
      "True  tensor([ 7, 22, 28,  1,  6], device='cuda:0')\n",
      "Epoch [56/100], Loss: 1.8672, Accuracy: 0.7411\n",
      "predicted tensor([ 1, 31, 33,  5,  7], device='cuda:0')\n",
      "True  tensor([ 1, 31, 33,  5,  7], device='cuda:0')\n",
      "Epoch [57/100], Loss: 1.8328, Accuracy: 0.7435\n",
      "predicted tensor([29, 28,  5, 16, 17], device='cuda:0')\n",
      "True  tensor([29, 31,  5, 16, 17], device='cuda:0')\n",
      "Epoch [58/100], Loss: 1.8144, Accuracy: 0.7435\n",
      "predicted tensor([29, 18, 18,  5,  7], device='cuda:0')\n",
      "True  tensor([29, 23, 18,  5,  7], device='cuda:0')\n",
      "Epoch [59/100], Loss: 1.7878, Accuracy: 0.7506\n",
      "predicted tensor([29, 27, 16, 15, 33], device='cuda:0')\n",
      "True  tensor([29, 27, 16, 15, 33], device='cuda:0')\n",
      "Epoch [60/100], Loss: 1.7572, Accuracy: 0.7601\n",
      "predicted tensor([ 4,  1, 26, 19,  1], device='cuda:0')\n",
      "True  tensor([11,  1, 21, 19,  1], device='cuda:0')\n",
      "Epoch [61/100], Loss: 1.7363, Accuracy: 0.7577\n",
      "predicted tensor([ 0, 28, 20, 18, 33], device='cuda:0')\n",
      "True  tensor([33, 31, 25, 18, 33], device='cuda:0')\n",
      "Epoch [62/100], Loss: 1.7214, Accuracy: 0.7648\n",
      "predicted tensor([33, 31,  1, 29,  1], device='cuda:0')\n",
      "True  tensor([33, 31,  1, 29,  1], device='cuda:0')\n",
      "Epoch [63/100], Loss: 1.6999, Accuracy: 0.7530\n",
      "predicted tensor([ 2, 20, 32, 26, 17], device='cuda:0')\n",
      "True  tensor([ 2, 20, 32, 26, 22], device='cuda:0')\n",
      "Epoch [64/100], Loss: 1.6824, Accuracy: 0.7530\n",
      "predicted tensor([10, 30, 33, 32,  3], device='cuda:0')\n",
      "True  tensor([10, 30, 33, 32,  3], device='cuda:0')\n",
      "Epoch [65/100], Loss: 1.6491, Accuracy: 0.7886\n",
      "predicted tensor([33,  4, 19, 26,  3], device='cuda:0')\n",
      "True  tensor([ 0,  4, 19, 26,  3], device='cuda:0')\n",
      "Epoch [66/100], Loss: 1.6328, Accuracy: 0.7601\n",
      "predicted tensor([26, 32,  4, 27, 12], device='cuda:0')\n",
      "True  tensor([21, 32,  4, 27, 12], device='cuda:0')\n",
      "Epoch [67/100], Loss: 1.6091, Accuracy: 0.7625\n",
      "predicted tensor([31,  1,  5,  4, 27], device='cuda:0')\n",
      "True  tensor([31,  1,  5, 11, 27], device='cuda:0')\n",
      "Epoch [68/100], Loss: 1.6014, Accuracy: 0.7553\n",
      "predicted tensor([ 5, 33, 20,  8, 18], device='cuda:0')\n",
      "True  tensor([ 5, 33, 20,  8, 18], device='cuda:0')\n",
      "Epoch [69/100], Loss: 1.5605, Accuracy: 0.7838\n",
      "predicted tensor([27, 33, 11, 20,  5], device='cuda:0')\n",
      "True  tensor([27, 33, 11, 25, 12], device='cuda:0')\n",
      "Epoch [70/100], Loss: 1.5479, Accuracy: 0.7720\n",
      "predicted tensor([ 3, 17, 33, 20,  4], device='cuda:0')\n",
      "True  tensor([ 3, 17,  0, 20, 11], device='cuda:0')\n",
      "Epoch [71/100], Loss: 1.5340, Accuracy: 0.7743\n",
      "predicted tensor([ 1, 33,  5, 16, 27], device='cuda:0')\n",
      "True  tensor([ 1, 29, 12, 16, 27], device='cuda:0')\n",
      "Epoch [72/100], Loss: 1.5077, Accuracy: 0.7672\n",
      "predicted tensor([ 7, 18, 19, 33,  1], device='cuda:0')\n",
      "True  tensor([ 7, 23, 24, 29,  1], device='cuda:0')\n",
      "Epoch [73/100], Loss: 1.4957, Accuracy: 0.7791\n",
      "predicted tensor([ 1, 24, 20,  7,  6], device='cuda:0')\n",
      "True  tensor([ 1, 24, 25, 14,  6], device='cuda:0')\n",
      "Epoch [74/100], Loss: 1.4785, Accuracy: 0.7720\n",
      "predicted tensor([26, 17, 20,  8, 32], device='cuda:0')\n",
      "True  tensor([21, 17, 20,  8, 32], device='cuda:0')\n",
      "Epoch [75/100], Loss: 1.4607, Accuracy: 0.7696\n",
      "predicted tensor([33, 26, 18,  8,  7], device='cuda:0')\n",
      "True  tensor([33, 21, 18,  8, 14], device='cuda:0')\n",
      "Epoch [76/100], Loss: 1.4376, Accuracy: 0.7743\n",
      "predicted tensor([32,  8,  1, 28, 31], device='cuda:0')\n",
      "True  tensor([32,  8,  1, 28, 31], device='cuda:0')\n",
      "Epoch [77/100], Loss: 1.4222, Accuracy: 0.7838\n",
      "predicted tensor([26, 27,  7,  4,  5], device='cuda:0')\n",
      "True  tensor([26, 27,  7,  4,  5], device='cuda:0')\n",
      "Epoch [78/100], Loss: 1.4083, Accuracy: 0.7910\n",
      "predicted tensor([18, 27, 20, 17,  7], device='cuda:0')\n",
      "True  tensor([23, 27, 25, 22,  7], device='cuda:0')\n",
      "Epoch [79/100], Loss: 1.3793, Accuracy: 0.7886\n",
      "predicted tensor([27, 33,  3, 18, 32], device='cuda:0')\n",
      "True  tensor([27,  0,  3, 18, 32], device='cuda:0')\n",
      "Epoch [80/100], Loss: 1.3645, Accuracy: 0.7886\n",
      "predicted tensor([27, 29,  8, 17, 33], device='cuda:0')\n",
      "True  tensor([27, 29,  8, 17, 33], device='cuda:0')\n",
      "Epoch [81/100], Loss: 1.3448, Accuracy: 0.7743\n",
      "predicted tensor([19, 20, 27, 16, 33], device='cuda:0')\n",
      "True  tensor([19, 25, 27, 16,  0], device='cuda:0')\n",
      "Epoch [82/100], Loss: 1.3396, Accuracy: 0.7791\n",
      "predicted tensor([17, 13, 20, 28, 12], device='cuda:0')\n",
      "True  tensor([17, 13, 25, 28, 12], device='cuda:0')\n",
      "Epoch [83/100], Loss: 1.3194, Accuracy: 0.7767\n",
      "predicted tensor([ 1,  6, 19, 26, 32], device='cuda:0')\n",
      "True  tensor([ 1, 13, 19, 21, 32], device='cuda:0')\n",
      "Epoch [84/100], Loss: 1.3074, Accuracy: 0.7815\n",
      "predicted tensor([26, 28,  1, 32,  1], device='cuda:0')\n",
      "True  tensor([21, 28,  1, 32,  1], device='cuda:0')\n",
      "Epoch [85/100], Loss: 1.2967, Accuracy: 0.7625\n",
      "predicted tensor([29, 20, 28, 33,  3], device='cuda:0')\n",
      "True  tensor([29, 25, 28, 33,  3], device='cuda:0')\n",
      "Epoch [86/100], Loss: 1.2712, Accuracy: 0.7933\n",
      "predicted tensor([19, 33,  7,  1, 28], device='cuda:0')\n",
      "True  tensor([24, 33,  7,  1, 28], device='cuda:0')\n",
      "Epoch [87/100], Loss: 1.2642, Accuracy: 0.7791\n",
      "predicted tensor([20, 33,  5, 29,  5], device='cuda:0')\n",
      "True  tensor([25,  0,  5, 29,  5], device='cuda:0')\n",
      "Epoch [88/100], Loss: 1.2419, Accuracy: 0.7957\n",
      "predicted tensor([17, 13, 13, 31, 28], device='cuda:0')\n",
      "True  tensor([17, 13, 13, 31, 28], device='cuda:0')\n",
      "Epoch [89/100], Loss: 1.2344, Accuracy: 0.7791\n",
      "predicted tensor([ 9, 31,  6, 18,  3], device='cuda:0')\n",
      "True  tensor([ 9, 31, 13, 23,  3], device='cuda:0')\n",
      "Epoch [90/100], Loss: 1.2073, Accuracy: 0.7933\n",
      "predicted tensor([31, 30, 27,  0,  6], device='cuda:0')\n",
      "True  tensor([31, 30, 27, 33, 13], device='cuda:0')\n",
      "Epoch [91/100], Loss: 1.1948, Accuracy: 0.7910\n",
      "predicted tensor([ 5, 15,  1,  7, 28], device='cuda:0')\n",
      "True  tensor([12, 15,  1,  7, 28], device='cuda:0')\n",
      "Epoch [92/100], Loss: 1.1868, Accuracy: 0.7791\n",
      "predicted tensor([28,  9, 33, 26, 26], device='cuda:0')\n",
      "True  tensor([28,  9,  0, 21, 26], device='cuda:0')\n",
      "Epoch [93/100], Loss: 1.1646, Accuracy: 0.8029\n",
      "predicted tensor([32, 30, 20, 17,  1], device='cuda:0')\n",
      "True  tensor([32, 30, 25, 17,  1], device='cuda:0')\n",
      "Epoch [94/100], Loss: 1.1624, Accuracy: 0.7767\n",
      "predicted tensor([ 2,  4, 30, 14, 17], device='cuda:0')\n",
      "True  tensor([ 2,  4, 30, 14, 22], device='cuda:0')\n",
      "Epoch [95/100], Loss: 1.1514, Accuracy: 0.7910\n",
      "predicted tensor([17,  9, 31, 20, 10], device='cuda:0')\n",
      "True  tensor([22,  9, 31, 25, 10], device='cuda:0')\n",
      "Epoch [96/100], Loss: 1.1423, Accuracy: 0.7981\n",
      "predicted tensor([27, 29, 26, 16,  9], device='cuda:0')\n",
      "True  tensor([27, 29, 21, 16,  9], device='cuda:0')\n",
      "Epoch [97/100], Loss: 1.1209, Accuracy: 0.7743\n",
      "predicted tensor([17,  7,  1,  2, 32], device='cuda:0')\n",
      "True  tensor([22, 14,  1,  2, 32], device='cuda:0')\n",
      "Epoch [98/100], Loss: 1.1151, Accuracy: 0.7743\n",
      "predicted tensor([29,  2, 31, 26, 17], device='cuda:0')\n",
      "True  tensor([29,  2, 31, 21, 17], device='cuda:0')\n",
      "Epoch [99/100], Loss: 1.1053, Accuracy: 0.7815\n",
      "predicted tensor([17, 28, 33,  2,  3], device='cuda:0')\n",
      "True  tensor([17, 28,  0,  9,  3], device='cuda:0')\n",
      "Epoch [100/100], Loss: 1.0855, Accuracy: 0.7791\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define Loss Function (replace with your desired loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define Optimizer\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    for inputs, attention_mask , labels in train_loader:\n",
    "       \n",
    "        \n",
    "        # Move inputs and labels to device\n",
    "        labels = labels.to(device)\n",
    "     \n",
    "        inputs = inputs.view(inputs.shape[0], MAX_length).to(device)\n",
    "   \n",
    "        attention_mask = attention_mask.to(device)\n",
    "       \n",
    "        # Forward pass\n",
    "        outputs = model(inputs, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Calculate accuracy\n",
    "    print(\"predicted\",predicted)\n",
    "    print(\"True \",labels)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    # ... (Track and print training progress)\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_dataset):.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba65b645-016f-49f8-85e6-5a5866f089fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('question_vs_statement_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5697cbfa-1744-4596-956a-75cf5e0f9e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " greetings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was nice to serve you']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what do you sell?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My name is Alphabot, I was created by ALPHA COMPUTER STORE to help our customers tom make thier descisions about shopping for our products']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " How can I order?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You can shop and order our products at our website https://www.alpha-computer.com']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " do you sell ram ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We offer many models of graphics cards this is a list of our top requisted products:\\n\\n1- Colorful iGame GeForce RTX 3050 Ultra W DUO OC 8G-V 8GB GDDR6 Graphics Card \\n price: 11999LE\\n\\n2- GALAX GeForce RTX 3060 8GB 1-Click OC 8GB GDDR6 Graphics Card \\n price: 13500LE\\n\\n3- GALAX GeForce RTX 3060 Ti LHR 1-Click OC Feature 8GB GDDR6 Graphics Card \\n price: 16900LE\\n\\n4- Colorful GeForce GTX 1660 SUPER NB 6GB V2-V GDDR6 Graphics Card \\n price: 8900LE\\n\\n5- COLORFUL IGAME GEFORCE RTX 3060 ULTRA W OC 12G L-V Graphics Card \\n price: 15000LE\\n\\n6- ASUS TUF Gaming GeForce RTX 3090 OC 24G \\n price: 39500LE\\n\\n7- GIGABAYT GeForce RTX 2060 WINDFORCE OC 12G \\n price: 10999LE\\n\\n']\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 27\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     newMessage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     ourResult \u001b[38;5;241m=\u001b[39m getRes(newMessage)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\mostafa_gp\\chatbot\\torchenv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\mostafa_gp\\chatbot\\torchenv\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def getRes(message):\n",
    "    encoding = tokenizer(message,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt')\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "       \n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    output = model(input_ids, attention_mask)\n",
    "    predicted = torch.argmax(output.logits ,1)\n",
    "    tag = train_dataset.label_encoder.inverse_transform(predicted.cpu())\n",
    "    for intent in data[\"intents\"]:\n",
    "\n",
    "        if intent[\"tag\"] == tag[0]:\n",
    "            print(intent[\"responses\"])\n",
    "            break\n",
    "       \n",
    " \n",
    "\n",
    "\n",
    "while True:\n",
    "    newMessage = input(\"\")\n",
    "    ourResult = getRes(newMessage)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5849e326-5131-424b-8222-c96fe3a789fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m453\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m654\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(torch.tensor([10,453,654,8,6,3]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d85fe2-c087-43d1-b868-85748c85e497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
